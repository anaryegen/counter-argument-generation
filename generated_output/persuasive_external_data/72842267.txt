Subscribe To Newsletters

This is a BETA experience. You may opt-out by clicking here

Sep 25, 2024,12:17am EDTPoetic Irony That OpenAI o1 New Superpower Artificially Convinces You That Pigs Can Fly

Sep 24, 2024,07:46pm EDTThe Ownership Issue: Three Big Questions With New AI Models

Sep 24, 2024,09:30am EDTHow Tomorrow’s Chatbots Will Reshape Our Daily Life

Sep 23, 2024,09:45pm EDTAI Hallucinations Invade OpenAI Latest GPT Model o1 In Quite Surprising Places

Sep 23, 2024,01:37pm EDT5 Easy Ways To Tell If A Video Came From Generative AI

Sep 22, 2024,07:11pm EDTThe New UN Global Digital Compact. What It Is, And Why We Matter.

Sep 22, 2024,06:39pm EDTWhy Some Are Predicting That Governor Newsom Is Going To Veto That AI ‘Existential Risk’ Bill Pending In California

Sep 21, 2024,05:31pm EDTBeyond Misinformation: The Impact Of AI In Journalism And News

5 Moral Dilemmas That Self-Driving Cars Face Today

Opinions expressed by Forbes Contributors are their own.

Aug 5, 2022,07:30am EDT

This article is more than 2 years old.

Suppose you are driving within the speed limits on the road. Out of nowhere, you see a child running across the road. You make the calculations and figure out that even if you applied the brakes real hard, you’d still hit the child. The only way to save him is to steer your vehicle either left or right. However, there are a dozen bystanders on either side of the road. You’ll definitely end up ramming into them.

So, what would you do in such a situation? Would you hit the child or the dozen bystanders? Or, if possible, disregard your own safety to prevent causing harm to either the child or the innocent people by the side of the road?

This dilemma is already difficult for humans to answer in a morally-correct manner. But what if autonomous or self-driving cars face such a moral dilemma? You have got to wonder, “What are the ethics of self-driving cars in such cases?” What will they do? Will they spare the child, the bystanders, and risk the driver’s life?

Putting the Ethics of Self-Driving Cars to the Test

In 2020, there were 35,766 fatal motor vehicle crashes in the United States. This led to the death of 38,824 people. Human error is cited as the leading cause of motor vehicle accidents. Using autonomous vehicles can help prevent many of these accidents.

However, one might argue that studies have shown that even with autonomous vehicles, accidents do happen. And as per a study, 99% of autonomous vehicle accidents are caused by human error. But, if you look at the report in-depth, you’ll find out that the accident was caused by a human in another vehicle or a pedestrian. There have been two cases where the self-driving car’s system was at fault for the accident.

So, it can be concluded that self-driving cars are more reliable than their manual counterparts. That being said, there are still certain dilemmas that self-driving cars face today, which raises a question about the ethics of self-driving cars and makes us wonder if we really are ready for a driverless future. Let’s take a look.

MORE FROMFORBES ADVISOR

Best High-Yield Savings Accounts Of 2024By

Best 5% Interest Savings Accounts of 2024By

Five Moral Dilemmas Self-Driving Cars Face Today

The moral dilemmas of self-driving cars are not new. Since their inception, the ethics of self-driving cars have been a hot topic of debate. Here is a look at five moral dilemmas self-driving cars still face today.

Predetermined Decisions Over Random Decisions in All Cases

Self-driving cars are basically robots that have been programmed using algorithms. So, they are most likely to follow set rules or patterns in all cases. However, that may not be the best course of action in all situations. Some people may argue, and right to some degree, that random accidents caused by humans are more justified than the predetermined death of a human or animal, in the case of an autonomous car.

So, in such cases, who is responsible for the death(s) caused? Is it the self-driving car manufacturer? Is it the software programmer? Or is it the car itself?

There is no clear and right answer to this question. Thus, most people feel that accidents should happen naturally rather than letting a robot or software decide who’ll live and die.

Giving Control to the Driver

Tesla requires the driver to keep their hands on the steering and be attentive, even when the vehicle is running in fully autonomous mode. The driver needs to be prepared to take over at any moment.

But, even in such cases, if an accident does happen, who is responsible for the loss of life and property? Is it the autonomous car that led to the accident? Or is it the driver who couldn’t take the appropriate decision in the nick of time? Or is it the reckless pedestrian or driver in another car?

Thus, one of the biggest dilemmas of self-driving cars is whether it would be right to hand over the control to the driver at the last instant. This will not only raise a question about the ethics of self-driving cars but also about the ethics of the driver.

Rightful Deciders of the Ethics of Self-Driving Cars

Generally, the ethics of self-driving cars are determined by the engineers who work on the car’s technology. What they deem right or wrong determines how the car will act in certain situations like accidents.

But, people argue about who is the right person or organization to decide the ethics of self-driving cars. Is it the engineers who worked on the car technology? Is it the government of the country where the vehicle will be driven?

It can be argued that no one is the right owner to decide the ethics of self-driving cases. The decision must lie in the hands of the driver of the car.

Program the Car to Make an Impartial Decision

Some also argue that the best way for a self-driving car is to make an impartial decision in case of accidents. They must not discriminate between humans based on age, gender, or other parameters. They should always make a decision that causes the least impact.

For example, if the car has to decide between saving a child or a group of sexagenarians, it should choose the sexagenarians as it will help save more lives. Moreover, human lives should be given priority over animal lives. Germany has become the first country to adopt such rules regarding self-driving cars. It has prioritized human lives above all other factors.

There is always a risk of a cyber criminal hacking into the car’s system to gain access to sensitive data or to carry out a misdeed. For example, what if the autonomous car is hacked by a cybercriminal and commanded to carry out an accident to implicate the driver? In such cases, who is responsible for the accident and loss of lives?

Is it the cybercriminal? Is it the driver? Is it the car manufacturer who couldn’t secure the car against such attacks? Due to such increased risks and unclear answers, self-driving cars, as a whole, may seem unethical to society.

5 Moral Dilemmas That Self Driving Cars Face TodayAllerin

The ethics of self-driving cars has been constantly under debate. The ethics have been defended and attacked to the extreme by supporters at each end of the spectrum. There is still no clear answer yet on how to solve the moral dilemmas self-driving cars face.

As the debate around the topic intensifies due to the increasing adoption of self-driving cars, we hope that strict laws and regulations will be developed that can finally answer the questions in a correct, justifiable manner.

Follow me on Twitter or LinkedIn. Check out my website. 

Join The Conversation

One Community. Many Voices. Create a free account to share your thoughts. Read our community guidelines here.

Forbes Community Guidelines

Our community is about connecting people through open and thoughtful conversations. We want our readers to share their views and exchange ideas and facts in a safe space.

In order to do so, please follow the posting rules in our site's Terms of Service. We've summarized some of those key rules below. Simply put, keep it civil.

Your post will be rejected if we notice that it seems to contain:

False or intentionally out-of-context or misleading information

Insults, profanity, incoherent, obscene or inflammatory language or threats of any kind

Attacks on the identity of other commenters or the article's author

Content that otherwise violates our site's terms.

User accounts will be blocked if we notice or believe that users are engaged in:

Continuous attempts to re-post comments that have been previously moderated/rejected

Racist, sexist, homophobic or other discriminatory comments

Attempts or tactics that put the site security at risk

Actions that otherwise violate our site's terms.

So, how can you be a power user?

Stay on topic and share your insights

Feel free to be clear and thoughtful to get your point across

‘Like’ or ‘Dislike’ to show your point of view.

Protect your community.

Use the report tool to alert us when someone breaks the rules.

Thanks for reading our community guidelines. Please read the full list of posting rules found in our site's Terms of Service.